{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping completed. Data saved to Flipkart_Laptops.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store the scraped data\n",
    "Productname = []\n",
    "Prices = []\n",
    "Description = []\n",
    "Reviews = []\n",
    "MRP = []\n",
    "TRR = []\n",
    "img_link = []\n",
    "\n",
    "# Function to scrape data from a single page\n",
    "def scrapping(soup):\n",
    "    table = soup.find(\"div\", class_=\"DOjaWF gdgoEp\")\n",
    "    \n",
    "    # Extract Product Names\n",
    "    names = table.find_all(\"div\", class_=\"KzDlHZ\")\n",
    "    for i in names:\n",
    "        name = i.text\n",
    "        Productname.append(name)\n",
    "\n",
    "    # Extract Image Links\n",
    "    img = table.find_all(\"img\", class_=\"DByuf4\")\n",
    "    for i in img:\n",
    "        img_link.append(i['src'])\n",
    "\n",
    "    # Extract Prices\n",
    "    prices = table.find_all(\"div\", class_=\"Nx9bqj _4b5DiR\")\n",
    "    for i in prices:\n",
    "        Prices.append(i.text)\n",
    "\n",
    "    # Extract Description\n",
    "    description = table.find_all(\"ul\", class_=\"G4BRas\")\n",
    "    for i in description:\n",
    "        Description.append(i.text)\n",
    "\n",
    "    # Extract Reviews\n",
    "    review = table.find_all(\"div\", class_=\"XQDdHH\")\n",
    "    for i in review:\n",
    "        Reviews.append(i.text)\n",
    "\n",
    "    # Extract MRP\n",
    "    mrp = table.find_all(\"div\", class_=\"yRaY8j ZYYwLA\")\n",
    "    for i in mrp:\n",
    "        MRP.append(i.text)\n",
    "\n",
    "    # Extract Total Number of Reviews and Ratings\n",
    "    crr = table.find_all(\"span\", class_=\"Wphh3N\")\n",
    "    for i in crr:\n",
    "        TRR.append(i.text)\n",
    "\n",
    "# Function to get the next page URL\n",
    "def get_next_page(soup):\n",
    "    next_button = soup.find('a', class_='_1LKTO3', string='Next')\n",
    "    if next_button:\n",
    "        return 'https://www.flipkart.com' + next_button['href']\n",
    "    return None\n",
    "\n",
    "# Starting URL\n",
    "url = 'https://www.flipkart.com/search?q=laptops&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&as-pos=1&as-type=HISTORY'\n",
    "\n",
    "# Loop through pages\n",
    "while url:\n",
    "    response = requests.get(url).content\n",
    "    soup = BeautifulSoup(response, 'lxml')\n",
    "    scrapping(soup)\n",
    "    url = get_next_page(soup)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "df = pd.DataFrame({\n",
    "    \"Product Name\": Productname,\n",
    "    \"Image Link\": img_link,\n",
    "    \"Price\": Prices,\n",
    "    \"Description\": Description,\n",
    "    \"Reviews\": Reviews,\n",
    "    \"MRP\": MRP,\n",
    "    \"Total Reviews and Rating\": TRR\n",
    "})\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv(\"Flipkart_Laptops.csv\", index=False)\n",
    "\n",
    "print(\"Scraping completed. Data saved to Flipkart_Laptops.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
